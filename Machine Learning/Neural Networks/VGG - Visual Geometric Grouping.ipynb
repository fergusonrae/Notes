{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Model\n",
    "\n",
    "## CNNs in General\n",
    "Currently, the best CNNs use small filter sizes with a greater number of layers.\n",
    "\n",
    "However, there is a diminshing rate of return with the number of layers of a CNN in relation to its filter size. Also, the more layers, generally the more complex and time consuming the model is.\n",
    "\n",
    "## Architecture\n",
    "VGG uses 3x3 filter and 16-19 layers and its creators believe this to be optimal. A 3x3 filter is the smallest size possible to still capture the notion of left/right, up/down, and center.\n",
    "\n",
    "\n",
    "\n",
    "During training, input is only 224x224 RGB images.\n",
    "\n",
    "\"The only preprocessing we do is subtracting the mean RGB value, computed on the training set, from each pixel.\" (Simonyan, Zimmerman pg. 2)\n",
    "\n",
    "\"Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed by max-pooling). Max-pooling is performed over a 2 × 2 pixel window, with stride 2.\" (Simonyan, Zimmerman pg. 2)\n",
    "\n",
    "\"three Fully-Connected (FC) layers: the first two have 4096 channels each, the third performs 1000-\n",
    "way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is\n",
    "the soft-max layer\" (Simonyan, Zimmerman pg. 2)\n",
    "\n",
    "## Training\n",
    "\n",
    "\"Optimising the multinomial logistic regression objective using mini-batch gradient descent (based on back-propagation (LeCun et al., 1989)) with momentum. The batch size was set to 256, momentum to 0.9. The training was regularised by weight decay (the L2 penalty multiplier set to 5 · 10−4) and dropout regularisation for the first two fully-connected layers (dropout ratio set to 0.5). The learning rate was initially set to 10^−2, and then decreased by a factor of 10 when the validation set accuracy stopped improving. In total, the learning rate was decreased 3 times, and the learning was stopped after 370K iterations (74 epochs). \" (Simonyan, Zimmerman pg. 4)\n",
    "\n",
    "It was believed that only 74 epochs were needed because of implicit regularization from having a small filter and many layers along with pre-initializatin of some of the layers.\n",
    "\n",
    "### Image Input for Training\n",
    "For the training images input, since the filter is a set size of 3x3, instead the images were \"zoomed in\" or scaled to reflect different attributes that they may contain. So, an input image is always 224x224 pixels. But, sometimes the image is scaled up, up to possibly 512x512, and then a smaller portion of 224x224 is used as the training image. This is done to ideally focus in on some attributes. All sorts of zooms between 224 and 512 are used to reflect the possibility of the style being reflected in different portions of the image.\n",
    "\n",
    "However, this scaling out is also computationally heavy because the amount of different \"slices\" of an image that you can get is much larger than the 1 image you can use without scaling. So, the first layers were set to be 256 to go faster and then final layers were adjusted to allow for more of a zoomed in image. Also, a smaller learning rate is used for the zoomed in images to speed things up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "**Title:** \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"  \n",
    "**Authors:** Karen Simonyan and Andrew Zisserman  \n",
    "**Date Published:** April 2015\n",
    "\n",
    "For future, research keras implementation and requirements / parameter tuning for that specific model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
